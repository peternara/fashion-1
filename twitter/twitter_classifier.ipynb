{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Blog post 4. Are you talking fashion? Building a fashion classifier for Twitter data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The explanation of this implementation can be found at: http://www.rosariomgomez.me/ <br><br>\n",
      "__Index:__<br>\n",
      "1. Collecting data<br>\n",
      "2. Vectorize tweets<br>\n",
      "3. Machine learning algorithms<br>\n",
      "4. Miscalssifications with Logistic Regression<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1. Collecting the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tweepy\n",
      "from tweepy.streaming import StreamListener\n",
      "from tweepy import OAuthHandler\n",
      "from tweepy import Stream\n",
      "from random import shuffle\n",
      "import numpy as np\n",
      "import json\n",
      "from time import sleep"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Twitter credentials\n",
      "consumer_key=\"\"\n",
      "consumer_secret=\"\"\n",
      "access_token=\"\"\n",
      "access_token_secret=\"\"\n",
      "\n",
      "#authentication process\n",
      "auth = OAuthHandler(consumer_key, consumer_secret)\n",
      "auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "#construct the API instance\n",
      "api = tweepy.API(auth)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''Create a client object to a mongod localhost instance and create or retrieve a database\n",
      "   Output: Database connection'''\n",
      "def get_db():\n",
      "    from pymongo import MongoClient\n",
      "    client = MongoClient('localhost:27017')\n",
      "    # create or retrieve the twitter database\n",
      "    db = client.twitter\n",
      "    return db\n",
      "\n",
      "'''Insert a tweet on the 'tweets' collection from the <db> database\n",
      "   Input: Database name, tweet dictionary'''\n",
      "def add_tweet(db, tweet):\n",
      "    if not db.tweets.find_one(tweet):\n",
      "        db.tweets.insert(tweet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1.1. Positive samples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a list of users ids from the fashion list\n",
      "# Iterate through all of the members on list using Cursor\n",
      "users = []\n",
      "for member in tweepy.Cursor(api.list_members, slug=\"fashion\", owner_screen_name=\"rosariomgomez\").items():\n",
      "    users.append(member.id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the 150 most recent tweets from user and store on the db\n",
      "def get_user_tweets(db, user, items=150):\n",
      "    for tweet in tweepy.Cursor(api.user_timeline, id=user).items(items):\n",
      "        add_tweet(db, {\"_id\": tweet.id, \"text\": tweet.text, \"is_fashion\": 1})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db = get_db()\n",
      "for user in users:\n",
      "    try:\n",
      "        get_user_tweets(db, user)\n",
      "    except tweepy.TweepError:\n",
      "        sleep(900) #15min sleep (Twitter rate limits for GET requests in API v.1.1: 15 calls every 15 minutes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1.2. Negative samples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class StdOutListener(StreamListener):\n",
      "    def __init__(self):\n",
      "        self.db = get_db()\n",
      "        \n",
      "    def on_data(self, data):\n",
      "        tweet = json.loads(data)\n",
      "        self.db.tweets.insert({\"_id\": tweet[\"id\"], \"text\": tweet[\"text\"], \"is_fashion\": 0})\n",
      "        return True\n",
      "\n",
      "    def on_error(self, status):\n",
      "        print status"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "listener = StdOutListener()\n",
      "stream = Stream(auth, listener)\n",
      "stream.filter(track=['mclaren', 'hybrid', 'python', 'recipe', 'race', 'robot', 'opera', 'gardening', 'democrats',\n",
      "                     'linux', 'brownie', 'airbus', 'nsa', 'police', '49ers', 'baseball', 'highway' ], languages=['en'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1.3. Building the data sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#retrieve all tweets from the database and create a data and label sets\n",
      "tweets = db.tweets.find()\n",
      "data = []\n",
      "labels = []\n",
      "for tweet in tweets:\n",
      "    data.append(tweet[\"text\"])\n",
      "    labels.append(tweet[\"is_fashion\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "31412\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "training_data, test_data, training_labels, test_labels = train_test_split(data, labels, test_size=0.3, random_state=0) #70-30 split\n",
      "print len(training_data), len(test_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21988 9424\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#we will split the training data into 2 more subsets: development and evaluation in order to first estimate the pipeline parameters\n",
      "#with the grid search and then evaluate the accuracy of the model with cross validation\n",
      "dev_data, eval_data, dev_labels, eval_labels = train_test_split(training_data, training_labels, test_size=0.5, random_state=0)\n",
      "print len(dev_data), len(eval_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10994 10994\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2-3. Vectorize tweets and Machine learning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "'''helper function for displaying best found features on grid_search'''\n",
      "def print_grid_search_metrics(gs):\n",
      "    print(\"Best score: %0.3f\" % gs.best_score_)\n",
      "    print(\"Best parameters set:\")\n",
      "    best_parameters = gs.best_params_\n",
      "    for param_name in sorted(parameters.keys()):\n",
      "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
      "        \n",
      "'''helper function for displaying the algorithm metrics'''\n",
      "def print_metrics(model_name, y_labels, y_predicted):\n",
      "    \n",
      "    print \"MODEL: \" + model_name\n",
      "    print 'Test Accuracy: ' + str(metrics.accuracy_score(y_labels, y_predicted))\n",
      "    \n",
      "    print '\\nClassification report:'\n",
      "    print classification_report(y_labels, y_predicted, target_names=['non-fashion tweets', 'fashion tweets'])\n",
      "    \n",
      "    print '\\nConfusion matrix:'\n",
      "    print metrics.confusion_matrix(y_labels, y_predicted)\n",
      "    \n",
      "'''helper to display the most informative features for each group'''\n",
      "def show_most_informative_features(vectorizer, clf, n=20):\n",
      "    feature_names = vectorizer.get_feature_names()\n",
      "    coefs_with_names = sorted(zip(clf.coef_[0], feature_names))\n",
      "    top_features = zip(coefs_with_names[:n], coefs_with_names[:-(n + 1):-1])  #top features for both groups\n",
      "    for (coef_1, fn_1), (coef_2, fn_2) in top_features:\n",
      "        print \"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
      "\n",
      "#add some tweets specific stop words to the built-in english list\n",
      "remove = ['amp', 'cc', 'did', 'don', 'rt', 'll', 'oh', 've', 'yes', 'let', 'going', 'via', 're', 'tweet' ]\n",
      "stop = list(ENGLISH_STOP_WORDS) + remove"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "from nltk.stem.snowball import *\n",
      "stemmer = SnowballStemmer('english')\n",
      "\n",
      "class NoUrls_TfidfVectorizer(TfidfVectorizer):\n",
      "    def build_preprocessor(self):\n",
      "        url_pattern = re.compile(r'http(s?)://[\\w./]+')\n",
      "        pic_pattern = re.compile(r'pic.twitter.com/[\\w.]+')\n",
      "        preprocessor = super(NoUrls_TfidfVectorizer, self).build_preprocessor()\n",
      "        return lambda doc: (pic_pattern.sub('', url_pattern.sub('', preprocessor(doc)) ))\n",
      "    \n",
      "class NoUrls_Stemmed_TfidfVectorizer(TfidfVectorizer):\n",
      "    def build_preprocessor(self):\n",
      "        url_pattern = re.compile(r'http(s?)://[\\w./]+')\n",
      "        pic_pattern = re.compile(r'pic.twitter.com/[\\w.]+')\n",
      "        preprocessor = super(NoUrls_Stemmed_TfidfVectorizer, self).build_preprocessor()\n",
      "        return lambda doc: (pic_pattern.sub('', url_pattern.sub('', preprocessor(doc)) ))\n",
      "    \n",
      "    def build_tokenizer(self):\n",
      "        tokenizer = super(NoUrls_Stemmed_TfidfVectorizer, self).build_tokenizer()\n",
      "        return lambda doc: (stemmer.stem(w) for w in tokenizer(doc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ngram_range: lower and upper boundary of the range of n-values for different n-grams to be extracted\n",
      "#I use words and bi-grams (to consider for example \"New York\" as unique feature)\n",
      "#min_df: ignore terms that have a term frequency strictly lower than the given threshold\n",
      "#because tweets are very short, we consider min_df=1 (consider all)\n",
      "tfidf = NoUrls_TfidfVectorizer(ngram_range=(1, 2), min_df=1, stop_words=stop, strip_accents='unicode')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Example process with an specific tweet\n",
      "tweet = u'rt @harpersbazaar The top 7 swimsuit trends of the season\u2014which will you wear? http://hbazaar.co/60109eOj pic.twitter.com/7J2hR4auMc #pretty'\n",
      "print 'Preprocess:', tfidf.build_preprocessor()(tweet)\n",
      "print\n",
      "print 'Analyze:', tfidf.build_analyzer()(tweet)\n",
      "tfidf.fit_transform([tweet])\n",
      "tfidf.vocabulary_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Preprocess: rt @harpersbazaar the top 7 swimsuit trends of the season\u2014which will you wear?   #pretty\n",
        "\n",
        "Analyze: [u'harpersbazaar', u'swimsuit', u'trend', u'season', u'wear', u'pretti', u'harpersbazaar swimsuit', u'swimsuit trend', u'trend season', u'season wear', u'wear pretti']\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "{u'harpersbazaar': 0,\n",
        " u'harpersbazaar swimsuit': 1,\n",
        " u'pretti': 2,\n",
        " u'season': 3,\n",
        " u'season wear': 4,\n",
        " u'swimsuit': 5,\n",
        " u'swimsuit trend': 6,\n",
        " u'trend': 7,\n",
        " u'trend season': 8,\n",
        " u'wear': 9,\n",
        " u'wear pretti': 10}"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.1. Bernoulli Naive Bayes classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.cross_validation import cross_val_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB\n",
      "Bern_classifier = BernoulliNB(binarize=None)\n",
      "Bern_pipeline = Pipeline([('tfidf', tfidf), ('clf', Bern_classifier)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Bern_classifier.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "{'alpha': 1.0, 'binarize': None, 'class_prior': None, 'fit_prior': True}"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.1.1. Feature selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#estimate the tfidf and classifier parameters by using grid search with a nested cross validation\n",
      "\n",
      "parameters = {\n",
      "    'tfidf__max_df': (0.8, 1.0),\n",
      "    'tfidf__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
      "    'tfidf__norm': ('l1', 'l2'),\n",
      "    'clf__alpha': (0.1, 0.5, 1)\n",
      "}\n",
      "\n",
      "bern_gs = GridSearchCV(Bern_pipeline, parameters, cv=5, verbose=1, refit=False)\n",
      "bern_gs.fit(dev_data, dev_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    3.7s\n",
        "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:  3.1min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  7.4min finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "GridSearchCV(cv=5,\n",
        "       estimator=Pipeline(steps=[('tfidf', NoUrls_TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "            charset_error=None, decode_error=u'strict',\n",
        "            dtype=<type 'numpy.int64'>, encoding=u'utf-8',\n",
        "            input=u'content', lowercase=True, max_df=1.0,\n",
        "            max_features=None, min_df=1, ...vocabulary=None)), ('clf', BernoulliNB(alpha=1.0, binarize=None, class_prior=None, fit_prior=True))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'tfidf__max_df': (0.8, 1.0), 'tfidf__norm': ('l1', 'l2'), 'tfidf__ngram_range': ((1, 1), (1, 2)), 'clf__alpha': (0.1, 0.5, 1)},\n",
        "       pre_dispatch='2*n_jobs', refit=False, score_func=None, scoring=None,\n",
        "       verbose=1)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_grid_search_metrics(bern_gs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best score: 0.955\n",
        "Best parameters set:\n",
        "\tclf__alpha: 0.5\n",
        "\ttfidf__max_df: 0.8\n",
        "\ttfidf__ngram_range: (1, 2)\n",
        "\ttfidf__norm: 'l2'\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.1.2. Model evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build the model with the best parameters set from the grid search\n",
      "Bern_vect = NoUrls_TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=0.8, norm='l2', stop_words=stop, strip_accents='unicode')\n",
      "Bern_classifier = BernoulliNB(alpha=0.5, binarize=None)\n",
      "Bern_pipeline = Pipeline([('tfidf', Bern_vect), ('clf', Bern_classifier)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#score: Array of scores of the estimator for each run of the cross validation\n",
      "score = cross_val_score(Bern_pipeline, eval_data, eval_labels, cv=10)\n",
      "print \"10-fold cross validation accuracy: \" + str(np.mean(score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10-fold cross validation accuracy: 0.949698817106\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.1.3. Test metrics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#now we build the final model with all the training data we have and predict the class for the testing data\n",
      "predictive_model = Bern_pipeline.fit(training_data, training_labels)\n",
      "y_Bern_predicted = Bern_pipeline.predict(test_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_metrics(\"Bernoulli Naive Bayes\", test_labels, y_Bern_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MODEL: Bernoulli Naive Bayes\n",
        "Test Accuracy: 0.964346349745\n",
        "\n",
        "Classification report:\n",
        "                    precision    recall  f1-score   support\n",
        "\n",
        "non-fashion tweets       0.97      0.96      0.96      4693\n",
        "    fashion tweets       0.96      0.97      0.96      4731\n",
        "\n",
        "       avg / total       0.96      0.96      0.96      9424\n",
        "\n",
        "\n",
        "Confusion matrix:\n",
        "[[4487  206]\n",
        " [ 130 4601]]\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_most_informative_features(Bern_vect, Bern_classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t-10.0195\t00 109         \t\t-4.7106\tnew            \n",
        "\t-10.0195\t00 12          \t\t-5.0410\tfashion        \n",
        "\t-10.0195\t00 15          \t\t-5.1579\tspring         \n",
        "\t-10.0195\t00 bids        \t\t-5.1903\ttoday          \n",
        "\t-10.0195\t00 finds       \t\t-5.1980\tlove           \n",
        "\t-10.0195\t00 gallon      \t\t-5.3214\tlook           \n",
        "\t-10.0195\t00 lincoln     \t\t-5.3766\tday            \n",
        "\t-10.0195\t00 pa          \t\t-5.4279\tthank          \n",
        "\t-10.0195\t00 purchase    \t\t-5.4301\tstyle          \n",
        "\t-10.0195\t00 thunder     \t\t-5.4485\tjust           \n",
        "\t-10.0195\t000 acquire    \t\t-5.4713\tthanks         \n",
        "\t-10.0195\t000 coin       \t\t-5.4778\tbest           \n",
        "\t-10.0195\t000 democrats  \t\t-5.5333\tlike           \n",
        "\t-10.0195\t000 gb         \t\t-5.6368\tweek           \n",
        "\t-10.0195\t000 info       \t\t-5.6411\tpost           \n",
        "\t-10.0195\t000 missing    \t\t-5.6555\tphoto          \n",
        "\t-10.0195\t000 pistol     \t\t-5.7137\ttime           \n",
        "\t-10.0195\t000 pot        \t\t-5.7828\thappy          \n",
        "\t-10.0195\t000 race       \t\t-5.8122\toutfit         \n",
        "\t-10.0195\t000 remark     \t\t-5.8530\tdress          \n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.2. Logistic regression classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "logistic_tfidf = NoUrls_TfidfVectorizer(min_df=1, stop_words=stop, strip_accents='unicode')\n",
      "logistic_classifier = LogisticRegression()\n",
      "logistic_pipeline = Pipeline([('tfidf', logistic_tfidf), ('clf', logistic_classifier)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logistic_classifier.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "{'C': 1.0,\n",
        " 'class_weight': None,\n",
        " 'dual': False,\n",
        " 'fit_intercept': True,\n",
        " 'intercept_scaling': 1,\n",
        " 'penalty': 'l2',\n",
        " 'random_state': None,\n",
        " 'tol': 0.0001}"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.2.1. Feature selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {\n",
      "    'tfidf__max_df': (0.8, 1.0),\n",
      "    'tfidf__ngram_range': ((1, 1), (1, 2)),\n",
      "    'tfidf__norm': ('l1', 'l2'),\n",
      "    'clf__C': (1, 5, 7)\n",
      "}\n",
      "\n",
      "logistic_gs = GridSearchCV(logistic_pipeline, parameters, verbose=1, refit=False)\n",
      "logistic_gs.fit(dev_data, dev_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    3.5s\n",
        "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:  3.1min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  4.5min finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=Pipeline(steps=[('tfidf', NoUrls_TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "            charset_error=None, decode_error=u'strict',\n",
        "            dtype=<type 'numpy.int64'>, encoding=u'utf-8',\n",
        "            input=u'content', lowercase=True, max_df=1.0,\n",
        "            max_features=None, min_df=1, ...e, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'tfidf__max_df': (0.8, 1.0), 'clf__C': (1, 5, 7), 'tfidf__norm': ('l1', 'l2'), 'tfidf__ngram_range': ((1, 1), (1, 2))},\n",
        "       pre_dispatch='2*n_jobs', refit=False, score_func=None, scoring=None,\n",
        "       verbose=1)"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_grid_search_metrics(logistic_gs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best score: 0.990\n",
        "Best parameters set:\n",
        "\tclf__C: 5\n",
        "\ttfidf__max_df: 0.8\n",
        "\ttfidf__ngram_range: (1, 1)\n",
        "\ttfidf__norm: 'l2'\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.2.2. Model evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build the model with the best parameters set from the grid search\n",
      "logistic_vect = NoUrls_TfidfVectorizer(ngram_range=(1, 1), min_df=1, max_df=0.8, norm='l2', stop_words=stop, strip_accents='unicode')\n",
      "logistic_classifier = LogisticRegression(C=5)\n",
      "logistic_pipeline = Pipeline([('tfidf', logistic_vect), ('clf', logistic_classifier)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#score: Array of scores of the estimator for each run of the cross validation\n",
      "score = cross_val_score(logistic_pipeline, eval_data, eval_labels, cv=10)\n",
      "print \"10-fold cross validation accuracy: \" + str(np.mean(score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10-fold cross validation accuracy: 0.987356274299\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.2.3. Test metrics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#now we build the final model with all the training data we have and predict the class for the testing data\n",
      "predictive_model = logistic_pipeline.fit(training_data, training_labels)\n",
      "y_logistic_predicted = logistic_pipeline.predict(test_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_metrics(\"Logistic Regression\", test_labels, y_logistic_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MODEL: Logistic Regression\n",
        "Test Accuracy: 0.990980475382\n",
        "\n",
        "Classification report:\n",
        "                    precision    recall  f1-score   support\n",
        "\n",
        "non-fashion tweets       0.99      0.99      0.99      4693\n",
        "    fashion tweets       0.99      0.99      0.99      4731\n",
        "\n",
        "       avg / total       0.99      0.99      0.99      9424\n",
        "\n",
        "\n",
        "Confusion matrix:\n",
        "[[4633   60]\n",
        " [  25 4706]]\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_most_informative_features(logistic_vect, logistic_classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t-39.8939\tbaseball       \t\t6.2993\tbrunch         \n",
        "\t-32.8749\tpolice         \t\t5.3912\tfashion        \n",
        "\t-32.1957\trace           \t\t4.4813\tnyfw           \n",
        "\t-20.0285\trecipe         \t\t4.0389\tstyle          \n",
        "\t-17.4650\tdemocrats      \t\t3.9377\trow            \n",
        "\t-16.6505\trobot          \t\t3.8305\tthank          \n",
        "\t-15.9959\thighway        \t\t3.8244\tyesterday      \n",
        "\t-14.5942\tnsa            \t\t3.6027\trapper         \n",
        "\t-14.3154\tbrownie        \t\t3.5777\tspring         \n",
        "\t-14.3127\topera          \t\t3.5750\tvoguemagazine  \n",
        "\t-13.4855\thybrid         \t\t3.5127\tdress          \n",
        "\t-13.4015\tlinux          \t\t3.3977\tbeauty         \n",
        "\t-12.9324\tgardening      \t\t3.3425\tchanel         \n",
        "\t-11.4597\t49ers          \t\t3.2145\tcollection     \n",
        "\t-10.4569\tpython         \t\t3.1684\tparis          \n",
        "\t-8.0506\tmclaren        \t\t3.0480\tdressed        \n",
        "\t-6.9610\tairbus         \t\t2.9573\tlove           \n",
        "\t-4.2125\tgame           \t\t2.9400\trunway         \n",
        "\t-4.1144\twin            \t\t2.9260\tsxsw           \n",
        "\t-3.7430\tcar            \t\t2.9141\toscars         \n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.3. Linear SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import LinearSVC\n",
      "SVM_tfidf = NoUrls_TfidfVectorizer(min_df=1, stop_words=stop, strip_accents='unicode')\n",
      "SVM_classifier = LinearSVC()\n",
      "SVM_pipeline = Pipeline([('tfidf', SVM_tfidf), ('clf', SVM_classifier)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SVM_classifier.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "{'C': 1.0,\n",
        " 'class_weight': None,\n",
        " 'dual': True,\n",
        " 'fit_intercept': True,\n",
        " 'intercept_scaling': 1,\n",
        " 'loss': 'l2',\n",
        " 'multi_class': 'ovr',\n",
        " 'penalty': 'l2',\n",
        " 'random_state': None,\n",
        " 'tol': 0.0001,\n",
        " 'verbose': 0}"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.3.1. Feature selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {\n",
      "    'tfidf__max_df': (0.8, 1.0),\n",
      "    'tfidf__ngram_range': ((1, 1), (1, 2)),\n",
      "    'tfidf__norm': ('l1', 'l2'),\n",
      "    'clf__C': (1, 5, 7)\n",
      "}\n",
      "\n",
      "SVM_gs = GridSearchCV(SVM_pipeline, parameters, verbose=1, refit=False)\n",
      "SVM_gs.fit(dev_data, dev_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    3.6s\n",
        "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:  3.1min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  4.4min finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=Pipeline(steps=[('tfidf', NoUrls_TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "            charset_error=None, decode_error=u'strict',\n",
        "            dtype=<type 'numpy.int64'>, encoding=u'utf-8',\n",
        "            input=u'content', lowercase=True, max_df=1.0,\n",
        "            max_features=None, min_df=1, ...ling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'tfidf__max_df': (0.8, 1.0), 'clf__C': (1, 5, 7), 'tfidf__norm': ('l1', 'l2'), 'tfidf__ngram_range': ((1, 1), (1, 2))},\n",
        "       pre_dispatch='2*n_jobs', refit=False, score_func=None, scoring=None,\n",
        "       verbose=1)"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_grid_search_metrics(SVM_gs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best score: 0.990\n",
        "Best parameters set:\n",
        "\tclf__C: 5\n",
        "\ttfidf__max_df: 0.8\n",
        "\ttfidf__ngram_range: (1, 1)\n",
        "\ttfidf__norm: 'l2'\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.3.2. Model evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build the model with the best parameters set from the grid search\n",
      "SVM_vect = NoUrls_TfidfVectorizer(ngram_range=(1, 1), min_df=1, max_df=0.8, norm='l2', stop_words=stop, strip_accents='unicode')\n",
      "SVM_classifier = LinearSVC(C=5)\n",
      "SVM_pipeline = Pipeline([('tfidf', SVM_vect), ('clf', SVM_classifier)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#score: Array of scores of the estimator for each run of the cross validation\n",
      "score = cross_val_score(SVM_pipeline, eval_data, eval_labels, cv=10)\n",
      "print \"10-fold cross validation accuracy: \" + str(np.mean(score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10-fold cross validation accuracy: 0.988720903301\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.3.3. Test metrics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#now we build the final model with all the training data we have and predict the class for the testing data\n",
      "predictive_model = SVM_pipeline.fit(training_data, training_labels)\n",
      "y_SVM_predicted = SVM_pipeline.predict(test_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_metrics(\"SVM\", test_labels, y_SVM_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MODEL: SVM\n",
        "Test Accuracy: 0.991511035654\n",
        "\n",
        "Classification report:\n",
        "                    precision    recall  f1-score   support\n",
        "\n",
        "non-fashion tweets       0.99      0.99      0.99      4693\n",
        "    fashion tweets       0.99      0.99      0.99      4731\n",
        "\n",
        "       avg / total       0.99      0.99      0.99      9424\n",
        "\n",
        "\n",
        "Confusion matrix:\n",
        "[[4644   49]\n",
        " [  31 4700]]\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_most_informative_features(SVM_vect, SVM_classifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t-14.1210\tbaseball       \t\t7.2903\tbrunch         \n",
        "\t-11.9195\trace           \t\t4.6183\tyesterday      \n",
        "\t-11.9044\tpolice         \t\t4.2024\trow            \n",
        "\t-7.1655\trecipe         \t\t3.6168\tbaseballdoucher\n",
        "\t-7.0651\tdemocrats      \t\t3.2017\trapper         \n",
        "\t-6.5867\trobot          \t\t2.6846\tnyfw           \n",
        "\t-6.5067\thighway        \t\t2.2212\tcertainly      \n",
        "\t-6.0213\tnsa            \t\t2.1878\tsenrandpaul    \n",
        "\t-6.0183\topera          \t\t2.0882\tdressed        \n",
        "\t-5.8695\tbrownie        \t\t1.8473\tparis          \n",
        "\t-5.7914\tlinux          \t\t1.7594\tstayed         \n",
        "\t-5.7502\thybrid         \t\t1.7474\tfrankcentrone  \n",
        "\t-5.3438\tgardening      \t\t1.7423\tmsrachelhollis \n",
        "\t-4.8445\t49ers          \t\t1.7389\tflair          \n",
        "\t-4.7230\tpython         \t\t1.7097\tstaple         \n",
        "\t-3.7592\tmclaren        \t\t1.7096\ttheme          \n",
        "\t-3.3689\tairbus         \t\t1.6891\tsydneyoperahouse\n",
        "\t-2.0326\tvote           \t\t1.6381\tswaps          \n",
        "\t-1.8247\tshowed         \t\t1.5574\tprime          \n",
        "\t-1.7162\tsis            \t\t1.5556\thmm            \n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4. Wrongly classified tweets with logistic regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wrong_classified = y_logistic_predicted != test_labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wrong_classified"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "array([False, False, False, ..., False, False, False], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wrong_data = test_data[wrong_classified == True]\n",
      "wrong_labels = y_logistic_predicted[wrong_classified == True]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "false_positive = wrong_data[wrong_labels == 1] #labeled as 1 (fashion) when should be 0 (non-fashion)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(false_positive)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "60"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#example tweet\n",
      "false_positive[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "u'@nationalgridus, thanks for destroying winter. @TWC, thanks for destroying spring baseball. Large corps, thanks for putting profit over ppl.'"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "false_negative = wrong_data[wrong_labels == 0]  #labeled as 0 (non-fashion) when they should belong to 1 (fashion)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(false_negative)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "25"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#example tweet\n",
      "false_negative[24]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "u'Help @VanityFair win a Webby! Keep us in 1st place in The #Webbys People\\u2019s Voice. VOTE: http://t.co/JQ8wC4OUPL'"
       ]
      }
     ],
     "prompt_number": 65
    }
   ],
   "metadata": {}
  }
 ]
}